{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer_learn.py\n",
    "# This program is an demo of using Transfer Learning.  Transfer learning let apply the power of an existing powerful\n",
    "# trained model to a dataset we are interested in.   In this example, we will use the Inveption-V3 model \n",
    "\n",
    "# create a folder named data.  Under that folder create the subfolders \"train\" and \"validate\"\n",
    "# Copy 1000 \"daisy\" files to the data/train/daisy folder, 1000 \"dandelion\" files to the data/train/dandelion folder.\n",
    "# Copy 400 different \"daisy\" files to the data/validate/daisy folder, 400 different \"dandelion\" files to the data/validate/dandelion folder.\n",
    "\n",
    "import os\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warning and informational messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count of number of files in this folder and all subfolders\n",
    "def get_num_files(path):\n",
    "  if not os.path.exists(path):\n",
    "    return 0\n",
    "  return sum([len(files) for r, d, files in os.walk(path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get count of number of subfolders directly below the folder in path\n",
    "def get_num_subfolders(path):\n",
    "  if not os.path.exists(path):\n",
    "    return 0\n",
    "  return sum([len(d) for r, d, files in os.walk(path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Define image generators that will variations of image with the image r/otated slightly, shifted up, down, left, or right, \n",
    "#   sheared, zoomed in, or flipped horizontally on the vertical axis (ie. person looking to the left ends up looking to the right)\n",
    "def create_img_generator():\n",
    "  return  ImageDataGenerator(\n",
    "      preprocessing_function=preprocess_input,\n",
    "      rotation_range=30,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Code\n",
    "Image_width, Image_height = 299, 299 \n",
    "Training_Epochs = 2\n",
    "Batch_Size = 32\n",
    "Number_FC_Neurons = 1024\n",
    "\n",
    "train_dir = './data/train'\n",
    "validate_dir = './data/validate'\n",
    "num_train_samples = get_num_files(train_dir) \n",
    "num_classes = get_num_subfolders(train_dir)\n",
    "num_validate_samples = get_num_files(validate_dir)\n",
    "num_epoch = Training_Epochs\n",
    "batch_size = Batch_Size\n",
    "\n",
    "# Define data pre-processing \n",
    "#   Define image generators for training and testing \n",
    "train_image_gen = create_img_generator()\n",
    "test_image_gen = create_img_generator()\n",
    "\n",
    "#   Connect the image generator to a folder contains the source images the image generator alters.  \n",
    "#   Training image generator\n",
    "train_generator = train_image_gen.flow_from_directory(\n",
    "  train_dir,\n",
    "  target_size=(Image_width, Image_height),\n",
    "  batch_size=batch_size,\n",
    "  seed = 42    #set seed for reproducability\n",
    ")\n",
    "\n",
    "#   Validation image generator\n",
    "validation_generator = test_image_gen.flow_from_directory(\n",
    "  validate_dir,\n",
    "  target_size=(Image_width, Image_height),\n",
    "  batch_size=batch_size,\n",
    "  seed=42       #set seed for reproducability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Inception V3 model and load it with it's pre-trained weights.  But exclude the final \n",
    "#    Fully Connected layer\n",
    "InceptionV3_base_model = InceptionV3(weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
    "print('Inception v3 base model without last FC loaded')\n",
    "#print(InceptionV3_base_model.summary())     # display the Inception V3 model hierarchy\n",
    "\n",
    "# Define the layers in the new classification prediction \n",
    "x = InceptionV3_base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(Number_FC_Neurons, activation='relu')(x)        # new FC layer, random init\n",
    "predictions = Dense(num_classes, activation='softmax')(x)  # new softmax layer\n",
    "\n",
    "# Define trainable model which links input from the Inception V3 base model to the new classification prediction layers\n",
    "model = Model(inputs=InceptionV3_base_model.input, outputs=predictions)\n",
    "\n",
    "# print model structure diagram\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transfer Learning with Fine-tuning - retrain the end few layers (called the top layers) of the inception model\n",
    "print('\\nFine tuning existing model')\n",
    "#   Freeze \n",
    "Layers_To_Freeze = 172\n",
    "for layer in model.layers[:Layers_To_Freeze]:\n",
    "  layer.trainable = False\n",
    "for layer in model.layers[Layers_To_Freeze:]:\n",
    "  layer.trainable = True\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the Fine-tuning model to the data from the generators.  \n",
    "# By using generators we can ask continue to request sample images and the generators will pull images from the training or validation\n",
    "# folders, alter then slightly, and pass the images back\n",
    "history_fine_tune = model.fit_generator(\n",
    "  train_generator,\n",
    "  steps_per_epoch = num_train_samples // batch_size,\n",
    "  epochs=num_epoch,\n",
    "  validation_data=validation_generator,\n",
    "  validation_steps = num_validate_samples // batch_size,\n",
    "    class_weight='auto')\n",
    "\n",
    "# Save fine tuned model\n",
    "model.save('inceptionv3-fine-tune.h5')\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
